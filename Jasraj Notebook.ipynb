{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_naless = cars.drop(columns=['Unnamed: 0', 'url', 'region_url', 'VIN', 'image_url', 'lat','long','posting_date']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_0_naless = cars_naless[cars_naless['price'] != 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_counts = cleaned_cars['description'].value_counts()\n",
    "desc_dict = desc_counts[desc_counts > 1].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_cars = cars_0_naless[(cars_0_naless['price'] < 300000) & (cars_0_naless['price'] > 100)]\n",
    "cleaned_cars = cleaned_cars[cleaned_cars['odometer'] < 500000]\n",
    "cleaned_cars['duplicate_descriptions'] = cleaned_cars['description'].apply(lambda x: desc_dict.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5,\n",
       " 0.8297872340425532,\n",
       " 0.8085106382978723,\n",
       " 0.9893617021276596,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.8404255319148937,\n",
       " 0.8723404255319149,\n",
       " 0.9574468085106383,\n",
       " 0.9893617021276596,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.8617021276595744,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9361702127659575,\n",
       " 0.8404255319148937,\n",
       " 0.851063829787234,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.9680851063829787,\n",
       " 0.9787234042553191,\n",
       " 0.9468085106382979,\n",
       " 0.9893617021276596,\n",
       " 0.9680851063829787,\n",
       " 0.6914893617021277,\n",
       " 0.8085106382978723,\n",
       " 0.43617021276595747,\n",
       " 0.9468085106382979,\n",
       " 0.8829787234042553,\n",
       " 0.9787234042553191,\n",
       " 0.8829787234042553,\n",
       " 0.851063829787234,\n",
       " 0.9574468085106383,\n",
       " 0.8829787234042553,\n",
       " 0.8723404255319149,\n",
       " 0.7978723404255319,\n",
       " 0.8085106382978723,\n",
       " 0.9042553191489362,\n",
       " 0.851063829787234,\n",
       " 0.8617021276595744,\n",
       " 0.9574468085106383,\n",
       " 0.7978723404255319,\n",
       " 0.851063829787234,\n",
       " 0.9148936170212766,\n",
       " 0.925531914893617,\n",
       " 0.8297872340425532,\n",
       " 0.8404255319148937,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.7872340425531915,\n",
       " 0.8404255319148937,\n",
       " 0.8085106382978723,\n",
       " 0.9787234042553191,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.8085106382978723,\n",
       " 0.8404255319148937,\n",
       " 0.7553191489361702,\n",
       " 0.8191489361702128,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.9042553191489362,\n",
       " 0.851063829787234,\n",
       " 0.8829787234042553,\n",
       " 0.7872340425531915,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.8191489361702128,\n",
       " 0.8617021276595744,\n",
       " 0.8723404255319149,\n",
       " 0.9361702127659575,\n",
       " 0.8297872340425532,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.8829787234042553,\n",
       " 0.8617021276595744,\n",
       " 0.776595744680851,\n",
       " 0.851063829787234,\n",
       " 0.8936170212765957,\n",
       " 0.8829787234042553,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.851063829787234,\n",
       " 0.851063829787234,\n",
       " 0.9574468085106383,\n",
       " 0.8617021276595744,\n",
       " 0.648936170212766,\n",
       " 0.8191489361702128,\n",
       " 0.8191489361702128,\n",
       " 0.8297872340425532,\n",
       " 0.8191489361702128,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.8829787234042553,\n",
       " 0.9574468085106383,\n",
       " 0.8297872340425532,\n",
       " 0.8191489361702128,\n",
       " 0.8617021276595744,\n",
       " 0.8936170212765957,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.7978723404255319,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.8936170212765957,\n",
       " 0.8617021276595744,\n",
       " 0.776595744680851,\n",
       " 0.8617021276595744,\n",
       " 0.8723404255319149,\n",
       " 0.9574468085106383,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.8617021276595744,\n",
       " 0.8297872340425532,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.8829787234042553,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.851063829787234,\n",
       " 0.8191489361702128,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.7021276595744681,\n",
       " 0.648936170212766,\n",
       " 0.8191489361702128,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.8829787234042553,\n",
       " 0.8723404255319149,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.925531914893617,\n",
       " 0.7446808510638298,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.8617021276595744,\n",
       " 0.9680851063829787,\n",
       " 0.9042553191489362,\n",
       " 0.8723404255319149,\n",
       " 0.7446808510638298,\n",
       " 0.8829787234042553,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.851063829787234,\n",
       " 0.8297872340425532,\n",
       " 0.851063829787234,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.7978723404255319,\n",
       " 0.8936170212765957,\n",
       " 0.9042553191489362,\n",
       " 0.8404255319148937,\n",
       " 0.9787234042553191,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.9361702127659575,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.7659574468085106,\n",
       " 0.776595744680851,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.925531914893617,\n",
       " 0.9680851063829787,\n",
       " 0.8936170212765957,\n",
       " 0.9787234042553191,\n",
       " 0.7978723404255319,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.776595744680851,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8936170212765957,\n",
       " 0.9042553191489362,\n",
       " 0.9361702127659575,\n",
       " 0.8191489361702128,\n",
       " 0.8829787234042553,\n",
       " 0.851063829787234,\n",
       " 0.925531914893617,\n",
       " 0.851063829787234,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.8191489361702128,\n",
       " 0.9574468085106383,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.9574468085106383,\n",
       " 0.8085106382978723,\n",
       " 0.8829787234042553,\n",
       " 0.8191489361702128,\n",
       " 0.9680851063829787,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.7978723404255319,\n",
       " 0.7659574468085106,\n",
       " 0.8936170212765957,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.925531914893617,\n",
       " 0.776595744680851,\n",
       " 0.9680851063829787,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.9787234042553191,\n",
       " 0.8617021276595744,\n",
       " 0.4148936170212766,\n",
       " 0.8936170212765957,\n",
       " 0.5212765957446809,\n",
       " 0.8297872340425532,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.8936170212765957,\n",
       " 0.9148936170212766,\n",
       " 0.851063829787234,\n",
       " 0.8829787234042553,\n",
       " 0.9148936170212766,\n",
       " 0.8936170212765957,\n",
       " 0.9468085106382979,\n",
       " 0.7978723404255319,\n",
       " 0.8723404255319149,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.9787234042553191,\n",
       " 0.9680851063829787,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.9468085106382979,\n",
       " 0.8723404255319149,\n",
       " 0.8191489361702128,\n",
       " 0.8404255319148937,\n",
       " 0.9361702127659575,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.7446808510638298,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.8085106382978723,\n",
       " 0.9148936170212766,\n",
       " 0.425531914893617,\n",
       " 0.7978723404255319,\n",
       " 0.8404255319148937,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.925531914893617,\n",
       " 0.9042553191489362,\n",
       " 0.8404255319148937,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.9787234042553191,\n",
       " 0.9787234042553191,\n",
       " 0.8617021276595744,\n",
       " 0.925531914893617,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.7446808510638298,\n",
       " 0.925531914893617,\n",
       " 0.9680851063829787,\n",
       " 0.776595744680851,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.851063829787234,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.8191489361702128,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.7446808510638298,\n",
       " 0.8617021276595744,\n",
       " 0.9574468085106383,\n",
       " 0.8191489361702128,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.8936170212765957,\n",
       " 0.9787234042553191,\n",
       " 0.9680851063829787,\n",
       " 0.9148936170212766,\n",
       " 0.8829787234042553,\n",
       " 0.925531914893617,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.9787234042553191,\n",
       " 0.9574468085106383,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.8617021276595744,\n",
       " 0.9787234042553191,\n",
       " 0.851063829787234,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.851063829787234,\n",
       " 0.8936170212765957,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8297872340425532,\n",
       " 0.7978723404255319,\n",
       " 0.8297872340425532,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.8404255319148937,\n",
       " 0.8723404255319149,\n",
       " 0.8829787234042553,\n",
       " 0.8936170212765957,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.8404255319148937,\n",
       " 0.9042553191489362,\n",
       " 0.9361702127659575,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.9787234042553191,\n",
       " 0.7872340425531915,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.8404255319148937,\n",
       " 0.8297872340425532,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.8191489361702128,\n",
       " 0.7978723404255319,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8829787234042553,\n",
       " 0.9787234042553191,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.8617021276595744,\n",
       " 0.8723404255319149,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.9787234042553191,\n",
       " 0.8404255319148937,\n",
       " 0.851063829787234,\n",
       " 0.8404255319148937,\n",
       " 0.7021276595744681,\n",
       " 0.7978723404255319,\n",
       " 0.7978723404255319,\n",
       " 0.9042553191489362,\n",
       " 0.7021276595744681,\n",
       " 0.8191489361702128,\n",
       " 0.8085106382978723,\n",
       " 0.9148936170212766,\n",
       " 0.7659574468085106,\n",
       " 0.8936170212765957,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.9893617021276596,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.2978723404255319,\n",
       " 0.7553191489361702,\n",
       " 0.8191489361702128,\n",
       " 0.7659574468085106,\n",
       " 0.8191489361702128,\n",
       " 0.7872340425531915,\n",
       " 0.7553191489361702,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.851063829787234,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.8829787234042553,\n",
       " 0.8404255319148937,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.8723404255319149,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.9361702127659575,\n",
       " 0.8936170212765957,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.6595744680851063,\n",
       " 0.9361702127659575,\n",
       " 0.7872340425531915,\n",
       " 0.9042553191489362,\n",
       " 0.8191489361702128,\n",
       " 0.8297872340425532,\n",
       " 0.7978723404255319,\n",
       " 0.925531914893617,\n",
       " 0.7978723404255319,\n",
       " 0.776595744680851,\n",
       " 0.9680851063829787,\n",
       " 0.9148936170212766,\n",
       " 0.9680851063829787,\n",
       " 0.9680851063829787,\n",
       " 0.9468085106382979,\n",
       " 0.7659574468085106,\n",
       " 0.8191489361702128,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.7446808510638298,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.9680851063829787,\n",
       " 0.7659574468085106,\n",
       " 0.925531914893617,\n",
       " 0.8085106382978723,\n",
       " 0.9361702127659575,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.8936170212765957,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.9680851063829787,\n",
       " 0.9787234042553191,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.9361702127659575,\n",
       " 0.8404255319148937,\n",
       " 0.9361702127659575,\n",
       " 0.8617021276595744,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.8723404255319149,\n",
       " 0.9574468085106383,\n",
       " 0.851063829787234,\n",
       " 0.9468085106382979,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.8297872340425532,\n",
       " 0.7872340425531915,\n",
       " 0.8085106382978723,\n",
       " 0.8191489361702128,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.7340425531914894,\n",
       " 0.7872340425531915,\n",
       " 0.9148936170212766,\n",
       " 0.7978723404255319,\n",
       " 0.8723404255319149,\n",
       " 0.8297872340425532,\n",
       " 0.8297872340425532,\n",
       " 0.851063829787234,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.7978723404255319,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.8617021276595744,\n",
       " 0.8723404255319149,\n",
       " 0.9361702127659575,\n",
       " 0.851063829787234,\n",
       " 0.8829787234042553,\n",
       " 0.9361702127659575,\n",
       " 0.851063829787234,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8829787234042553,\n",
       " 0.9680851063829787,\n",
       " 0.9148936170212766,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.9468085106382979,\n",
       " 0.9148936170212766,\n",
       " 0.8936170212765957,\n",
       " 0.9574468085106383,\n",
       " 0.7340425531914894,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.9787234042553191,\n",
       " 0.9574468085106383,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8936170212765957,\n",
       " 0.8723404255319149,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.8723404255319149,\n",
       " 0.9787234042553191,\n",
       " 0.8297872340425532,\n",
       " 0.9148936170212766,\n",
       " 0.9148936170212766,\n",
       " 0.9148936170212766,\n",
       " 0.925531914893617,\n",
       " 0.925531914893617,\n",
       " 0.8723404255319149,\n",
       " 0.925531914893617,\n",
       " 0.7978723404255319,\n",
       " 0.9680851063829787,\n",
       " 0.8829787234042553,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.8085106382978723,\n",
       " 0.8297872340425532,\n",
       " 0.851063829787234,\n",
       " 0.9680851063829787,\n",
       " 0.9148936170212766,\n",
       " 0.7446808510638298,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.8936170212765957,\n",
       " 0.2872340425531915,\n",
       " 0.8723404255319149,\n",
       " 0.7021276595744681,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.7340425531914894,\n",
       " 0.8936170212765957,\n",
       " 0.851063829787234,\n",
       " 0.9042553191489362,\n",
       " 0.7553191489361702,\n",
       " 0.9042553191489362,\n",
       " 0.925531914893617,\n",
       " 0.8297872340425532,\n",
       " 0.8404255319148937,\n",
       " 0.8404255319148937,\n",
       " 0.9574468085106383,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.8191489361702128,\n",
       " 0.9574468085106383,\n",
       " 0.8936170212765957,\n",
       " 0.8191489361702128,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9680851063829787,\n",
       " 0.925531914893617,\n",
       " 0.8829787234042553,\n",
       " 0.9574468085106383,\n",
       " 0.8085106382978723,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.8404255319148937,\n",
       " 0.8191489361702128,\n",
       " 0.9574468085106383,\n",
       " 0.8936170212765957,\n",
       " 0.7978723404255319,\n",
       " 0.8617021276595744,\n",
       " 0.7659574468085106,\n",
       " 0.8936170212765957,\n",
       " 0.925531914893617,\n",
       " 0.7659574468085106,\n",
       " 0.9680851063829787,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.925531914893617,\n",
       " 0.9361702127659575,\n",
       " 0.8085106382978723,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.8297872340425532,\n",
       " 0.8829787234042553,\n",
       " 0.44680851063829785,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9574468085106383,\n",
       " 0.9787234042553191,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9787234042553191,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9680851063829787,\n",
       " 0.9787234042553191,\n",
       " 0.9787234042553191,\n",
       " 0.8191489361702128,\n",
       " 0.8723404255319149,\n",
       " 0.9680851063829787,\n",
       " 0.8829787234042553,\n",
       " 0.8829787234042553,\n",
       " 0.8936170212765957,\n",
       " 0.851063829787234,\n",
       " 0.8085106382978723,\n",
       " 0.8085106382978723,\n",
       " 0.8191489361702128,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.9787234042553191,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.8936170212765957,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.7978723404255319,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.851063829787234,\n",
       " 0.8191489361702128,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.9361702127659575,\n",
       " 0.8829787234042553,\n",
       " 0.776595744680851,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.851063829787234,\n",
       " 0.851063829787234,\n",
       " 0.8617021276595744,\n",
       " 0.7978723404255319,\n",
       " 0.8297872340425532,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.925531914893617,\n",
       " 0.9148936170212766,\n",
       " 0.8404255319148937,\n",
       " 0.925531914893617,\n",
       " 0.8829787234042553,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.8723404255319149,\n",
       " 0.925531914893617,\n",
       " 0.925531914893617,\n",
       " 0.8297872340425532,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.8085106382978723,\n",
       " 0.9787234042553191,\n",
       " 0.8085106382978723,\n",
       " 0.7872340425531915,\n",
       " 0.9787234042553191,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.8936170212765957,\n",
       " 0.8617021276595744,\n",
       " 0.9468085106382979,\n",
       " 0.8085106382978723,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.851063829787234,\n",
       " 0.40425531914893614,\n",
       " 0.7978723404255319,\n",
       " 0.8617021276595744,\n",
       " 0.9574468085106383,\n",
       " 0.8936170212765957,\n",
       " 0.5531914893617021,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.9574468085106383,\n",
       " 0.9574468085106383,\n",
       " 0.7127659574468085,\n",
       " 0.9574468085106383,\n",
       " 0.9574468085106383,\n",
       " 0.9680851063829787,\n",
       " 0.9574468085106383,\n",
       " 0.9680851063829787,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.851063829787234,\n",
       " 0.7446808510638298,\n",
       " 0.851063829787234,\n",
       " 0.8297872340425532,\n",
       " 0.9680851063829787,\n",
       " 0.9574468085106383,\n",
       " 0.8936170212765957,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.8404255319148937,\n",
       " 0.9787234042553191,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.8829787234042553,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9148936170212766,\n",
       " 0.8297872340425532,\n",
       " 0.9787234042553191,\n",
       " 0.8936170212765957,\n",
       " 0.8829787234042553,\n",
       " 0.9468085106382979,\n",
       " 0.851063829787234,\n",
       " 0.8723404255319149,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.7872340425531915,\n",
       " 0.851063829787234,\n",
       " 0.851063829787234,\n",
       " 0.8404255319148937,\n",
       " 0.8829787234042553,\n",
       " 0.8829787234042553,\n",
       " 0.8617021276595744,\n",
       " 0.8723404255319149,\n",
       " 0.8085106382978723,\n",
       " 0.925531914893617,\n",
       " 0.9042553191489362,\n",
       " 0.851063829787234,\n",
       " 0.851063829787234,\n",
       " 0.9787234042553191,\n",
       " 0.9680851063829787,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8297872340425532,\n",
       " 0.925531914893617,\n",
       " 0.925531914893617,\n",
       " 0.8617021276595744,\n",
       " 0.9042553191489362,\n",
       " 0.925531914893617,\n",
       " 0.851063829787234,\n",
       " 0.8297872340425532,\n",
       " 0.8723404255319149,\n",
       " 0.8829787234042553,\n",
       " 0.8404255319148937,\n",
       " 0.9148936170212766,\n",
       " 0.8297872340425532,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.9574468085106383,\n",
       " 0.8191489361702128,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.9148936170212766,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8085106382978723,\n",
       " 0.8404255319148937,\n",
       " 0.7659574468085106,\n",
       " 0.9042553191489362,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.9361702127659575,\n",
       " 0.9148936170212766,\n",
       " 0.8617021276595744,\n",
       " 0.8404255319148937,\n",
       " 0.9148936170212766,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.9361702127659575,\n",
       " 0.7978723404255319,\n",
       " 0.9148936170212766,\n",
       " 0.6808510638297872,\n",
       " 0.8191489361702128,\n",
       " 0.8617021276595744,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.9361702127659575,\n",
       " 0.9468085106382979,\n",
       " 0.9148936170212766,\n",
       " 0.9361702127659575,\n",
       " 0.9361702127659575,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.8297872340425532,\n",
       " 0.9680851063829787,\n",
       " 0.9042553191489362,\n",
       " 0.8404255319148937,\n",
       " 0.9680851063829787,\n",
       " 0.9680851063829787,\n",
       " 0.9468085106382979,\n",
       " 0.925531914893617,\n",
       " 0.9468085106382979,\n",
       " 0.9680851063829787,\n",
       " 0.9361702127659575,\n",
       " 0.7659574468085106,\n",
       " 0.8829787234042553,\n",
       " 0.851063829787234,\n",
       " 0.8617021276595744,\n",
       " 0.8191489361702128,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.7659574468085106,\n",
       " 0.8191489361702128,\n",
       " 0.8936170212765957,\n",
       " 0.851063829787234,\n",
       " 0.9042553191489362,\n",
       " 0.776595744680851,\n",
       " 0.9574468085106383,\n",
       " 0.9680851063829787,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.8085106382978723,\n",
       " 0.9787234042553191,\n",
       " 0.9148936170212766,\n",
       " 0.9042553191489362,\n",
       " 0.9361702127659575,\n",
       " 0.925531914893617,\n",
       " 0.8617021276595744,\n",
       " 0.9361702127659575,\n",
       " 0.8723404255319149,\n",
       " 0.9042553191489362,\n",
       " 0.925531914893617,\n",
       " 0.9574468085106383,\n",
       " 0.925531914893617,\n",
       " 0.8617021276595744,\n",
       " 0.9042553191489362,\n",
       " 0.9468085106382979,\n",
       " 0.9574468085106383,\n",
       " 0.9574468085106383,\n",
       " 0.851063829787234,\n",
       " 0.9148936170212766,\n",
       " 0.9574468085106383,\n",
       " 0.9468085106382979,\n",
       " 0.9468085106382979,\n",
       " 0.9361702127659575,\n",
       " 0.8404255319148937,\n",
       " 0.8617021276595744,\n",
       " 0.925531914893617,\n",
       " 0.9361702127659575,\n",
       " 0.7659574468085106,\n",
       " 0.9680851063829787,\n",
       " 0.9574468085106383,\n",
       " 0.9148936170212766,\n",
       " 0.8829787234042553,\n",
       " 0.8829787234042553,\n",
       " 0.9787234042553191,\n",
       " 0.9468085106382979,\n",
       " 0.8936170212765957,\n",
       " 0.8617021276595744,\n",
       " 0.8936170212765957,\n",
       " 0.8936170212765957,\n",
       " 0.7553191489361702,\n",
       " 0.8297872340425532,\n",
       " 0.925531914893617,\n",
       " 0.8936170212765957,\n",
       " 0.9361702127659575,\n",
       " 0.851063829787234,\n",
       " 0.851063829787234,\n",
       " 0.8404255319148937,\n",
       " 0.9680851063829787,\n",
       " 0.9787234042553191,\n",
       " 0.9361702127659575,\n",
       " 0.9787234042553191,\n",
       " 0.8936170212765957,\n",
       " 0.9042553191489362,\n",
       " 0.9042553191489362,\n",
       " 0.9148936170212766,\n",
       " 0.851063829787234,\n",
       " 0.8936170212765957,\n",
       " 0.8617021276595744,\n",
       " 0.8617021276595744,\n",
       " 0.9148936170212766,\n",
       " 0.8723404255319149,\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_max = cleaned_cars['year'].max()\n",
    "year_min = cleaned_cars['year'].min()\n",
    "((cleaned_cars['year'] - year_min)/(year_max - year_min)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features Transforming\n",
    "# Numerical\n",
    "year = ((cleaned_cars['year'] - year_min)/(year_max - year_min)).tolist()\n",
    "odom = (cleaned_cars['odometer']/max(cleaned_cars['odometer'])).tolist()\n",
    "\n",
    "# Categorical/One Hot Encode\n",
    "manu = cleaned_cars['manufacturer'].unique().tolist()\n",
    "cond = cleaned_cars['condition'].unique().tolist()\n",
    "cycl = cleaned_cars['cylinders'].unique().tolist()\n",
    "fuel = cleaned_cars['fuel'].unique().tolist()\n",
    "tit = cleaned_cars['title_status'].unique().tolist()\n",
    "tran = cleaned_cars['transmission'].unique().tolist()\n",
    "drive = cleaned_cars['drive'].unique().tolist()\n",
    "size = cleaned_cars['size'].unique().tolist()\n",
    "typ = cleaned_cars['type'].unique().tolist()\n",
    "paint = cleaned_cars['paint_color'].unique().tolist()\n",
    "state = cleaned_cars['state'].unique().tolist()\n",
    "dupl = cleaned_cars['duplicate_descriptions'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot vector for each feature\n",
    "manu_One = np.zeros((len(cleaned_cars),len(manu)))\n",
    "cond_One = np.zeros((len(cleaned_cars),len(cond)))\n",
    "cycl_One = np.zeros((len(cleaned_cars),len(cycl)))\n",
    "fuel_One = np.zeros((len(cleaned_cars),len(fuel)))\n",
    "tit_One = np.zeros((len(cleaned_cars),len(tit)))\n",
    "tran_One = np.zeros((len(cleaned_cars),len(tran)))\n",
    "drive_One = np.zeros((len(cleaned_cars),len(drive)))\n",
    "size_One = np.zeros((len(cleaned_cars),len(size)))\n",
    "typ_One = np.zeros((len(cleaned_cars),len(typ)))\n",
    "paint_One = np.zeros((len(cleaned_cars),len(paint)))\n",
    "state_One = np.zeros((len(cleaned_cars),len(state)))\n",
    "dupl_One = np.zeros((len(cleaned_cars),len(dupl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform all features\n",
    "for x in range(len(cleaned_cars)):\n",
    "    manu_One[x][manu.index(cleaned_cars['manufacturer'].iloc[x])] = 1\n",
    "    cond_One[x][cond.index(cleaned_cars['condition'].iloc[x])] = 1\n",
    "    cycl_One[x][cycl.index(cleaned_cars['cylinders'].iloc[x])] = 1\n",
    "    fuel_One[x][fuel.index(cleaned_cars['fuel'].iloc[x])] = 1\n",
    "    tit_One[x][tit.index(cleaned_cars['title_status'].iloc[x])] = 1\n",
    "    tran_One[x][tran.index(cleaned_cars['transmission'].iloc[x])] = 1\n",
    "    drive_One[x][drive.index(cleaned_cars['drive'].iloc[x])] = 1\n",
    "    size_One[x][size.index(cleaned_cars['size'].iloc[x])] = 1\n",
    "    typ_One[x][typ.index(cleaned_cars['type'].iloc[x])] = 1\n",
    "    paint_One[x][paint.index(cleaned_cars['paint_color'].iloc[x])] = 1\n",
    "    state_One[x][state.index(cleaned_cars['state'].iloc[x])] = 1\n",
    "    dupl_One[x][dupl.index(cleaned_cars['duplicate_descriptions'].iloc[x])] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model category counts and transform them for those above 100\n",
    "categoryCounts = {}\n",
    "for x in cleaned_cars['model']:\n",
    "    if x not in categoryCounts.keys():\n",
    "        categoryCounts[x] = 0\n",
    "    categoryCounts[x] += 1\n",
    "categories = [c for c in categoryCounts if categoryCounts[c] > 100]\n",
    "catID = dict(zip(list(categories),range(len(categories))))\n",
    "\n",
    "mod_One = np.zeros((len(cleaned_cars),len(catID.keys())))\n",
    "for x in range(len(cleaned_cars)):\n",
    "    if cleaned_cars['model'].iloc[x] in catID.keys():\n",
    "        mod_One[x][catID[cleaned_cars['model'].iloc[x]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all features to append\n",
    "car_columns = [year,\n",
    "               odom,\n",
    "               manu_One,\n",
    "               mod_One,\n",
    "               cond_One,\n",
    "               cycl_One,\n",
    "               fuel_One,\n",
    "               tit_One,\n",
    "               tran_One,\n",
    "               drive_One,\n",
    "               size_One,\n",
    "               typ_One,\n",
    "               paint_One,\n",
    "               state_One,\n",
    "               dupl_One]\n",
    "\n",
    "# array to put all features in\n",
    "clean_car_data = np.array([])\n",
    "\n",
    "for i in car_columns:\n",
    "    if clean_car_data.size == 0:\n",
    "        clean_car_data = np.array([i]).reshape(-1, 1)\n",
    "    else:\n",
    "        data = np.array(i)\n",
    "        \n",
    "        if len(data.shape) == 1:\n",
    "            data = data.reshape(-1, 1)\n",
    "            \n",
    "        clean_car_data = np.concatenate((clean_car_data, data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "x_train, x_test, y_train, y_test = train_test_split(clean_car_data, cleaned_cars['price'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation and testing data\n",
    "x_valid, x_test, y_valid, y_test = train_test_split(x_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return np.sqrt(sum(differences) / len(differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make and train linear regression model\n",
    "lin_reg_model = LinearRegression(fit_intercept=True)\n",
    "lin_reg_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7015.781470508533"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on train\n",
    "lin_reg_train_preds = lin_reg_model.predict(x_train)\n",
    "lin_reg_train_RMSE = RMSE(lin_reg_train_preds, y_train)\n",
    "lin_reg_train_RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7040.70049790455"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on validation\n",
    "lin_reg_valid_preds = lin_reg_model.predict(x_valid)\n",
    "lin_reg_valid_RMSE = RMSE(lin_reg_valid_preds, y_valid)\n",
    "lin_reg_valid_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(columns_list):\n",
    "    \"\"\"Creates all features to put into a features list.\"\"\"\n",
    "\n",
    "    # array to put all features in\n",
    "    clean_car_data = np.array([])\n",
    "\n",
    "    for i in columns_list:\n",
    "        if clean_car_data.size == 0:\n",
    "            data = np.array(i)\n",
    "            \n",
    "            if len(data.shape) == 1:\n",
    "                data = data.reshape(-1, 1)\n",
    "                \n",
    "            clean_car_data = data\n",
    "        else:\n",
    "            data = np.array(i)\n",
    "            \n",
    "            if len(data.shape) == 1:\n",
    "                data = data.reshape(-1, 1)\n",
    "\n",
    "            clean_car_data = np.concatenate((clean_car_data, data), axis=1)\n",
    "\n",
    "    return clean_car_data\n",
    "\n",
    "def get_evaluations(x_train, x_valid, y_train, y_valid):\n",
    "    \"\"\"Train and test using data\"\"\"\n",
    "    # Make and train linear regression model\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict on train\n",
    "    train_preds = model.predict(x_train)\n",
    "    train_RMSE = RMSE(train_preds, y_train)\n",
    "    \n",
    "    # Predict on validation\n",
    "    valid_preds = model.predict(x_valid)\n",
    "    valid_RMSE = RMSE(valid_preds, y_valid)\n",
    "    \n",
    "    return model, train_RMSE, valid_RMSE\n",
    "    \n",
    "def find_ablation(columns_list, y):\n",
    "    \"\"\"Find the best columns through ablation.\"\"\"\n",
    "    \n",
    "    all_models = {}\n",
    "\n",
    "    all_features = create_features(columns_list)\n",
    "\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(all_features, y, test_size=0.3, random_state=42)\n",
    "    x_va, x_te, y_va, y_te = train_test_split(x_te, y_te, test_size=0.5, random_state=42)\n",
    "\n",
    "    temp_model, tr_RMSE, va_RMSE = get_evaluations(x_tr, x_va, y_tr, y_va)\n",
    "\n",
    "    all_models['all'] = temp_model\n",
    "    print(\"With all features: Train RMSE \" + str(tr_RMSE) + \" | Valid RMSE \" + str(va_RMSE))\n",
    "    \n",
    "    for i in range(len(columns_list)):\n",
    "        modded_list = columns_list.copy()\n",
    "        modded_list.pop(i)\n",
    "        \n",
    "        all_features = create_features(modded_list)\n",
    "        \n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(all_features, y, test_size=0.3, random_state=42)\n",
    "        x_va, x_te, y_va, y_te = train_test_split(x_te, y_te, test_size=0.5, random_state=42)\n",
    "        \n",
    "        temp_model, tr_RMSE, va_RMSE = get_evaluations(x_tr, x_va, y_tr, y_va)\n",
    "        \n",
    "        all_models[i] = temp_model\n",
    "        print(\"Without feature \" + str(i) + \": Train RMSE \" + str(tr_RMSE) + \" | Valid RMSE \" + str(va_RMSE))\n",
    "    \n",
    "    return all_models\n",
    "\n",
    "def find_double_ablation(columns_list, y):\n",
    "    \"\"\"Find the best columns through ablation.\"\"\"\n",
    "    \n",
    "    all_models = {}\n",
    "\n",
    "    all_features = create_features(columns_list)\n",
    "\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(all_features, y, test_size=0.3, random_state=42)\n",
    "    x_va, x_te, y_va, y_te = train_test_split(x_te, y_te, test_size=0.5, random_state=42)\n",
    "\n",
    "    temp_model, tr_RMSE, va_RMSE = get_evaluations(x_tr, x_va, y_tr, y_va)\n",
    "\n",
    "    all_models['all'] = temp_model\n",
    "    print(\"With all features: Train RMSE \" + str(tr_RMSE) + \" | Valid RMSE \" + str(va_RMSE))\n",
    "    \n",
    "    for i in range(len(columns_list)):\n",
    "        for j in range(i, len(columns_list) - 1):\n",
    "            modded_list = columns_list.copy()\n",
    "            modded_list.pop(i)\n",
    "            modded_list.pop(j)\n",
    "\n",
    "            all_features = create_features(modded_list)\n",
    "\n",
    "            x_tr, x_te, y_tr, y_te = train_test_split(all_features, y, test_size=0.3, random_state=42)\n",
    "            x_va, x_te, y_va, y_te = train_test_split(x_te, y_te, test_size=0.5, random_state=42)\n",
    "\n",
    "            temp_model, tr_RMSE, va_RMSE = get_evaluations(x_tr, x_va, y_tr, y_va)\n",
    "\n",
    "            all_models[(i, j)] = temp_model\n",
    "            print(\"Without features \" + str(i) + \" and \" + str(j+1) +\n",
    "                  \": Train RMSE \" + str(tr_RMSE) + \" | Valid RMSE \" + str(va_RMSE))\n",
    "\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ablation_columns = [year,\n",
    "               odom,\n",
    "               manu_One,\n",
    "               mod_One,\n",
    "               cond_One,\n",
    "               cycl_One,\n",
    "               fuel_One,\n",
    "               tit_One,\n",
    "               tran_One,\n",
    "               drive_One,\n",
    "               size_One,\n",
    "               typ_One,\n",
    "               paint_One,\n",
    "               state_One]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_ablation_columns = [year,\n",
    "               odom,\n",
    "               manu_One,\n",
    "               mod_One,\n",
    "               cond_One,\n",
    "               cycl_One,\n",
    "               fuel_One,\n",
    "               tit_One,\n",
    "               tran_One,\n",
    "               drive_One,\n",
    "               size_One,\n",
    "               typ_One,\n",
    "               paint_One,\n",
    "               state_One,\n",
    "               dupl_One]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With all features: Train RMSE 7038.197748807188 | Valid RMSE 7063.529033458708\n",
      "Without feature 0: Train RMSE 7361.667136782332 | Valid RMSE 7414.56143973078\n",
      "Without feature 1: Train RMSE 8061.65552326332 | Valid RMSE 8097.0450603902655\n",
      "Without feature 2: Train RMSE 7196.1995019767965 | Valid RMSE 7239.606426378233\n",
      "Without feature 3: Train RMSE 7177.803282577516 | Valid RMSE 7172.694704331935\n",
      "Without feature 4: Train RMSE 7111.353038217762 | Valid RMSE 7121.082530615473\n",
      "Without feature 5: Train RMSE 7109.989963311475 | Valid RMSE 7150.627393415714\n",
      "Without feature 6: Train RMSE 7215.9388225818175 | Valid RMSE 7270.555318267805\n",
      "Without feature 7: Train RMSE 7074.3815077868085 | Valid RMSE 7090.695223038541\n",
      "Without feature 8: Train RMSE 7049.010335884166 | Valid RMSE 7081.163468511664\n",
      "Without feature 9: Train RMSE 7109.233131143464 | Valid RMSE 7158.732899812135\n",
      "Without feature 10: Train RMSE 7045.3366058558495 | Valid RMSE 7070.384487710459\n",
      "Without feature 11: Train RMSE 7140.924774988746 | Valid RMSE 7151.6540761749575\n",
      "Without feature 12: Train RMSE 7048.749432795081 | Valid RMSE 7072.847486554487\n",
      "Without feature 13: Train RMSE 7097.981000756277 | Valid RMSE 7118.449164348779\n"
     ]
    }
   ],
   "source": [
    "first_ablation = find_ablation(first_ablation_columns, cleaned_cars['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With all features: Train RMSE 7015.781470508533 | Valid RMSE 7040.70049790455\n",
      "Without feature 0: Train RMSE 7338.961260745495 | Valid RMSE 7390.689041546563\n",
      "Without feature 1: Train RMSE 8036.3717049342 | Valid RMSE 8075.6634714021275\n",
      "Without feature 2: Train RMSE 7171.979275116932 | Valid RMSE 7214.1495300418665\n",
      "Without feature 3: Train RMSE 7149.513218913484 | Valid RMSE 7142.650908652812\n",
      "Without feature 4: Train RMSE 7090.259770669415 | Valid RMSE 7100.507956881796\n",
      "Without feature 5: Train RMSE 7087.509691040395 | Valid RMSE 7127.592110602163\n",
      "Without feature 6: Train RMSE 7191.730753864489 | Valid RMSE 7244.407149351614\n",
      "Without feature 7: Train RMSE 7052.200272589356 | Valid RMSE 7068.688837023177\n",
      "Without feature 8: Train RMSE 7026.69336167199 | Valid RMSE 7058.355424357105\n",
      "Without feature 9: Train RMSE 7086.9954888977345 | Valid RMSE 7134.763557904511\n",
      "Without feature 10: Train RMSE 7023.597934831996 | Valid RMSE 7048.59988727383\n",
      "Without feature 11: Train RMSE 7117.875332885606 | Valid RMSE 7127.9503421613335\n",
      "Without feature 12: Train RMSE 7026.600106585866 | Valid RMSE 7049.890570259244\n",
      "Without feature 13: Train RMSE 7076.203752072905 | Valid RMSE 7093.583126426771\n",
      "Without feature 14: Train RMSE 7038.197748807188 | Valid RMSE 7063.529033458708\n"
     ]
    }
   ],
   "source": [
    "second_ablation = find_ablation(second_ablation_columns, cleaned_cars['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With all features: Train RMSE 7038.197748807188 | Valid RMSE 7063.529033458708\n",
      "Without features 0 and 1: Train RMSE 8602.039307045397 | Valid RMSE 8674.089117351383\n",
      "Without features 0 and 2: Train RMSE 7512.598036257236 | Valid RMSE 7589.941954618639\n",
      "Without features 0 and 3: Train RMSE 7530.600317120363 | Valid RMSE 7547.057206575836\n",
      "Without features 0 and 4: Train RMSE 7505.756023759494 | Valid RMSE 7539.260005666788\n",
      "Without features 0 and 5: Train RMSE 7392.182994826418 | Valid RMSE 7457.166521293509\n",
      "Without features 0 and 6: Train RMSE 7540.623222235628 | Valid RMSE 7632.2178313696395\n",
      "Without features 0 and 7: Train RMSE 7396.962609406127 | Valid RMSE 7437.668877879769\n",
      "Without features 0 and 8: Train RMSE 7362.019735305869 | Valid RMSE 7415.20785529813\n",
      "Without features 0 and 9: Train RMSE 7455.381683165372 | Valid RMSE 7535.194052828997\n",
      "Without features 0 and 10: Train RMSE 7370.086937810868 | Valid RMSE 7418.874526859306\n",
      "Without features 0 and 11: Train RMSE 7455.3531264745525 | Valid RMSE 7483.907299883327\n",
      "Without features 0 and 12: Train RMSE 7394.474109578869 | Valid RMSE 7449.203001033047\n",
      "Without features 0 and 13: Train RMSE 7431.820104213705 | Valid RMSE 7478.395623493266\n",
      "Without features 1 and 2: Train RMSE 8196.25621548506 | Valid RMSE 8256.620685260035\n",
      "Without features 1 and 3: Train RMSE 8242.802383097263 | Valid RMSE 8247.433472690182\n",
      "Without features 1 and 4: Train RMSE 8370.0168765348 | Valid RMSE 8369.798587860969\n",
      "Without features 1 and 5: Train RMSE 8108.892066594588 | Valid RMSE 8150.953767320313\n",
      "Without features 1 and 6: Train RMSE 8162.159837157697 | Valid RMSE 8222.633520720328\n",
      "Without features 1 and 7: Train RMSE 8080.274273426014 | Valid RMSE 8113.14560047496\n",
      "Without features 1 and 8: Train RMSE 8073.311538529874 | Valid RMSE 8117.906929328194\n",
      "Without features 1 and 9: Train RMSE 8132.460864674253 | Valid RMSE 8196.492037228698\n",
      "Without features 1 and 10: Train RMSE 8067.315580077793 | Valid RMSE 8104.64916803098\n",
      "Without features 1 and 11: Train RMSE 8192.870669466745 | Valid RMSE 8208.64889723959\n",
      "Without features 1 and 12: Train RMSE 8078.06267690096 | Valid RMSE 8111.374385988365\n",
      "Without features 1 and 13: Train RMSE 8130.776899425724 | Valid RMSE 8158.188753101198\n",
      "Without features 2 and 3: Train RMSE 7369.964737558877 | Valid RMSE 7386.793286136434\n",
      "Without features 2 and 4: Train RMSE 7273.085580365948 | Valid RMSE 7299.414932036675\n",
      "Without features 2 and 5: Train RMSE 7286.966217166037 | Valid RMSE 7346.586314650401\n",
      "Without features 2 and 6: Train RMSE 7376.427861310064 | Valid RMSE 7447.71364610229\n",
      "Without features 2 and 7: Train RMSE 7231.848651094958 | Valid RMSE 7267.3355796561755\n",
      "Without features 2 and 8: Train RMSE 7208.3193850066755 | Valid RMSE 7259.3538242214645\n",
      "Without features 2 and 9: Train RMSE 7301.9142349064605 | Valid RMSE 7370.099197691065\n",
      "Without features 2 and 10: Train RMSE 7203.026934003442 | Valid RMSE 7246.719286043541\n",
      "Without features 2 and 11: Train RMSE 7310.96916134866 | Valid RMSE 7339.36363436075\n",
      "Without features 2 and 12: Train RMSE 7207.475082110306 | Valid RMSE 7250.714767258849\n",
      "Without features 2 and 13: Train RMSE 7258.379030934376 | Valid RMSE 7300.909241875067\n",
      "Without features 3 and 4: Train RMSE 7242.770007278052 | Valid RMSE 7222.049211563453\n",
      "Without features 3 and 5: Train RMSE 7285.264305202924 | Valid RMSE 7286.956692209467\n",
      "Without features 3 and 6: Train RMSE 7492.539144697391 | Valid RMSE 7511.175511453381\n",
      "Without features 3 and 7: Train RMSE 7215.29134861604 | Valid RMSE 7200.482349032664\n",
      "Without features 3 and 8: Train RMSE 7190.450275285998 | Valid RMSE 7193.365612765703\n",
      "Without features 3 and 9: Train RMSE 7263.601327993615 | Valid RMSE 7284.664847021215\n",
      "Without features 3 and 10: Train RMSE 7186.40952849037 | Valid RMSE 7180.5443156105075\n",
      "Without features 3 and 11: Train RMSE 7316.441899560729 | Valid RMSE 7299.856169249728\n",
      "Without features 3 and 12: Train RMSE 7191.1241287301345 | Valid RMSE 7184.117406552843\n",
      "Without features 3 and 13: Train RMSE 7240.168564991019 | Valid RMSE 7234.093568333671\n",
      "Without features 4 and 5: Train RMSE 7183.76749457311 | Valid RMSE 7210.823305389848\n",
      "Without features 4 and 6: Train RMSE 7290.161265175182 | Valid RMSE 7328.292667437086\n",
      "Without features 4 and 7: Train RMSE 7155.435737710836 | Valid RMSE 7154.188834883095\n",
      "Without features 4 and 8: Train RMSE 7122.109520848375 | Valid RMSE 7138.431822529554\n",
      "Without features 4 and 9: Train RMSE 7186.007686519505 | Valid RMSE 7219.437183306952\n",
      "Without features 4 and 10: Train RMSE 7119.988480310949 | Valid RMSE 7129.603986839405\n",
      "Without features 4 and 11: Train RMSE 7211.955534441391 | Valid RMSE 7210.089644357283\n",
      "Without features 4 and 12: Train RMSE 7122.281891593301 | Valid RMSE 7130.708037503257\n",
      "Without features 4 and 13: Train RMSE 7172.134915491978 | Valid RMSE 7178.872221125029\n",
      "Without features 5 and 6: Train RMSE 7278.138878903083 | Valid RMSE 7341.497400587968\n",
      "Without features 5 and 7: Train RMSE 7147.68483031876 | Valid RMSE 7179.730493059528\n",
      "Without features 5 and 8: Train RMSE 7117.332417554681 | Valid RMSE 7163.037451908541\n",
      "Without features 5 and 9: Train RMSE 7217.491246843185 | Valid RMSE 7288.015730226272\n",
      "Without features 5 and 10: Train RMSE 7135.231984727007 | Valid RMSE 7178.1122094880875\n",
      "Without features 5 and 11: Train RMSE 7261.447115362906 | Valid RMSE 7289.531130790052\n",
      "Without features 5 and 12: Train RMSE 7121.680241722033 | Valid RMSE 7162.415969418588\n",
      "Without features 5 and 13: Train RMSE 7174.048992756201 | Valid RMSE 7209.00446209582\n",
      "Without features 6 and 7: Train RMSE 7250.907372941029 | Valid RMSE 7296.987301218931\n",
      "Without features 6 and 8: Train RMSE 7227.807085881988 | Valid RMSE 7288.584754052957\n",
      "Without features 6 and 9: Train RMSE 7293.158995093546 | Valid RMSE 7370.594421459489\n",
      "Without features 6 and 10: Train RMSE 7226.301296894549 | Valid RMSE 7281.287657077007\n",
      "Without features 6 and 11: Train RMSE 7375.969419738215 | Valid RMSE 7411.78791124477\n",
      "Without features 6 and 12: Train RMSE 7226.602808525492 | Valid RMSE 7280.238865285826\n",
      "Without features 6 and 13: Train RMSE 7278.027841406928 | Valid RMSE 7327.101578655944\n",
      "Without features 7 and 8: Train RMSE 7085.733050254124 | Valid RMSE 7107.692921807147\n",
      "Without features 7 and 9: Train RMSE 7145.727338023763 | Valid RMSE 7186.81716859481\n",
      "Without features 7 and 10: Train RMSE 7080.661764494864 | Valid RMSE 7097.024258923405\n",
      "Without features 7 and 11: Train RMSE 7178.555784727886 | Valid RMSE 7180.020481410524\n",
      "Without features 7 and 12: Train RMSE 7084.888119647231 | Valid RMSE 7100.00678396891\n",
      "Without features 7 and 13: Train RMSE 7131.102204732 | Valid RMSE 7144.2682689586345\n",
      "Without features 8 and 9: Train RMSE 7120.263761109035 | Valid RMSE 7177.1243459996795\n",
      "Without features 8 and 10: Train RMSE 7055.304305855062 | Valid RMSE 7086.576426207071\n",
      "Without features 8 and 11: Train RMSE 7158.040844480355 | Valid RMSE 7176.6469942395815\n",
      "Without features 8 and 12: Train RMSE 7059.774103436328 | Valid RMSE 7090.884211451386\n",
      "Without features 8 and 13: Train RMSE 7109.158353839635 | Valid RMSE 7136.659241239193\n",
      "Without features 9 and 10: Train RMSE 7116.599066778293 | Valid RMSE 7166.4568489094645\n",
      "Without features 9 and 11: Train RMSE 7255.023576027182 | Valid RMSE 7300.237907295471\n",
      "Without features 9 and 12: Train RMSE 7120.361573937201 | Valid RMSE 7168.716451217876\n",
      "Without features 9 and 13: Train RMSE 7165.396928802157 | Valid RMSE 7206.086957175076\n",
      "Without features 10 and 11: Train RMSE 7147.911661672245 | Valid RMSE 7156.270071659159\n",
      "Without features 10 and 12: Train RMSE 7055.935596441669 | Valid RMSE 7079.560267859456\n",
      "Without features 10 and 13: Train RMSE 7103.346662570005 | Valid RMSE 7122.908814558333\n",
      "Without features 11 and 12: Train RMSE 7153.08655794698 | Valid RMSE 7163.202318686917\n",
      "Without features 11 and 13: Train RMSE 7204.45181221249 | Valid RMSE 7211.393158770631\n",
      "Without features 12 and 13: Train RMSE 7108.484765319029 | Valid RMSE 7128.330218212401\n"
     ]
    }
   ],
   "source": [
    "first_double_ablation = find_double_ablation(first_ablation_columns, cleaned_cars['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_50_columns = [year,\n",
    "               odom,\n",
    "               manu_One,\n",
    "               mod_One,\n",
    "               cond_One,\n",
    "               cycl_One,\n",
    "               fuel_One,\n",
    "               tit_One,\n",
    "               tran_One,\n",
    "               drive_One,\n",
    "               size_One,\n",
    "               typ_One,\n",
    "               paint_One,\n",
    "               state_One]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 6985.137285830318\n",
      "Valid RMSE 6912.987529889483\n"
     ]
    }
   ],
   "source": [
    "# Above 50 appearances for model feature\n",
    "limit_50_features = create_features(limit_50_columns)\n",
    "        \n",
    "x_tr_50, x_te_50, y_tr_50, y_te_50 = train_test_split(limit_50_features, cleaned_cars['price'], test_size=0.3, random_state=42)\n",
    "x_va_50, x_te_50, y_va_50, y_te_50 = train_test_split(x_te_50, y_te_50, test_size=0.3, random_state=42)\n",
    "        \n",
    "model_50, train_50_RMSE, valid_50_RMSE = get_evaluations(x_tr_50, x_va_50, y_tr_50, y_va_50)\n",
    "\n",
    "print(\"Train RMSE \" + str(train_50_RMSE))\n",
    "print(\"Valid RMSE \" + str(valid_50_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 6899.386262976084\n",
      "Valid RMSE 6856.100200443149\n"
     ]
    }
   ],
   "source": [
    "# Above 25 appearances for model feature\n",
    "limit_25_features = create_features(limit_25_columns)\n",
    "        \n",
    "x_tr_25, x_te_25, y_tr_25, y_te_25 = train_test_split(limit_25_features, cleaned_cars['price'], test_size=0.3, random_state=42)\n",
    "x_va_25, x_te_25, y_va_25, y_te_25 = train_test_split(x_te_25, y_te_25, test_size=0.3, random_state=42)\n",
    "        \n",
    "model_25, train_25_RMSE, valid_25_RMSE = get_evaluations(x_tr_25, x_va_25, y_tr_25, y_va_25)\n",
    "\n",
    "print(\"Train RMSE \" + str(train_25_RMSE))\n",
    "print(\"Valid RMSE \" + str(valid_25_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE 6475.5888129185805\n",
      "Valid RMSE 6634.978308415088\n"
     ]
    }
   ],
   "source": [
    "# Above 5 appearances for model feature\n",
    "limit_5_features = create_features(limit_5_columns)\n",
    "        \n",
    "x_tr_5, x_te_5, y_tr_5, y_te_5 = train_test_split(limit_5_features, cleaned_cars['price'], test_size=0.3, random_state=42)\n",
    "x_va_5, x_te_5, y_va_5, y_te_5 = train_test_split(x_te_5, y_te_5, test_size=0.3, random_state=42)\n",
    "        \n",
    "model_5, train_5_RMSE, valid_5_RMSE = get_evaluations(x_tr_5, x_va_5, y_tr_5, y_va_5)\n",
    "\n",
    "print(\"Train RMSE \" + str(train_5_RMSE))\n",
    "print(\"Valid RMSE \" + str(valid_5_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
